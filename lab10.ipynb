{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from treelib import Node, Tree\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICTACTOE_MAP = np.array([[1, 6, 5], [8, 4, 0], [3, 2, 7]])\n",
    "\n",
    "def tictactoe_map(set_pos):\n",
    "    return {TICTACTOE_MAP[pos//3,pos%3] for pos in set_pos}\n",
    "\n",
    "def display(x, o):\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            if (r*3+c) in x:\n",
    "                print(\"X\", end=\" \")\n",
    "            elif (r*3+c) in o:\n",
    "                print(\"O\", end=\" \")\n",
    "            else:\n",
    "                print(\".\", end=\" \")\n",
    "        print()\n",
    "\n",
    "def won(cells):\n",
    "    return any(sum(h) == 12 for h in permutations(tictactoe_map(cells), 3))\n",
    "\n",
    "def my_print(s):\n",
    "    print(s, flush=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "St = namedtuple('State', ['x', 'o','next_turn']) # x={}, o={}\n",
    "Ply = namedtuple('Ply', ['turn','pos'])\n",
    "\n",
    "def static_eval(state: St):\n",
    "    if won(state.x):\n",
    "        return 1\n",
    "    elif won(state.o):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states generated: 850\n",
      "actions generated: 2702\n"
     ]
    }
   ],
   "source": [
    "states_map={} # map (state, total reward)\n",
    "\n",
    "action_map={} # not present in lab10_b\n",
    "\n",
    "BIG_INT = 1_000_000_000\n",
    "DEBUG = False\n",
    "#position of x fit in 5bit variable, same for position of o, ply fit to 1bit variable\n",
    "#FROM PAPER: \"quixo is solved\"\n",
    "def from_xo_to_key(state: St) -> int:\n",
    "\n",
    "    key = 0\n",
    "\n",
    "    for pos in state.x:\n",
    "        key += 2**pos\n",
    "    for pos in state.o:\n",
    "        key += 2**(pos+9)\n",
    "    \n",
    "    key+= state.next_turn*(2**18)\n",
    "\n",
    "    return key\n",
    "\n",
    "def from_key_to_xo(key: int) -> St: \n",
    "\n",
    "    x ={bin_mask for bin_mask in range(9) if (key & 1<<bin_mask)!=0}\n",
    "    o ={bin_mask for bin_mask in range(9) if (key & 1<<(bin_mask+9))!=0}\n",
    "    next_turn = (key & (1<<18))>>18\n",
    "    \n",
    "    return St(x, o, next_turn)\n",
    "\n",
    "def from_board_to_xo(board: np.array((3,3), np.int8)) -> (set,set):\n",
    "\n",
    "    x = set([])\n",
    "    o = set([])\n",
    "    for i in range(board.shape[0]):\n",
    "        for j in range(board.shape[1]):\n",
    "            if board[i][j] == 0:\n",
    "                x |= {i*3+j}\n",
    "            elif board[i][j] == 1:\n",
    "                o |= {i*3+j}\n",
    "        \n",
    "    return (x, o)\n",
    "\n",
    "def from_xo_to_board(x: set, o:set) -> np.array((3,3), np.int8):\n",
    "    board = np.ones((3,3),dtype=np.int8)*-1\n",
    "    for pos in x:\n",
    "        board[pos//3][pos%3] = 0\n",
    "    for pos in o:\n",
    "        board[pos//3][pos%3] = 1\n",
    "    return board\n",
    "\n",
    "def calculate_equivalent(key: int) -> [int]:\n",
    "    \n",
    "    x, o, next_turn = from_key_to_xo(key)\n",
    "\n",
    "    board = np.ones((3,3), dtype=np.uint8) * -1\n",
    "    \n",
    "    for pos in x:\n",
    "        board[pos//3,pos%3] = 0\n",
    "    for pos in o:\n",
    "        board[pos//3,pos%3] = 1\n",
    "    \n",
    "    xo_set = from_board_to_xo(board)\n",
    "    xo_set_T = from_board_to_xo(board.T)\n",
    "\n",
    "    equiv_state_ids = [from_xo_to_key(St(xo_set[0],xo_set[1], next_turn)), from_xo_to_key(St(xo_set_T[0],xo_set_T[1], next_turn))]\n",
    "\n",
    "    for _ in range(3):\n",
    "\n",
    "        board = np.rot90(board)\n",
    "\n",
    "        xo_set = from_board_to_xo(board)\n",
    "        xo_set_T = from_board_to_xo(board.T)\n",
    "\n",
    "        equiv_state_ids.append(from_xo_to_key(St(xo_set[0],xo_set[1], next_turn)))\n",
    "        equiv_state_ids.append(from_xo_to_key(St(xo_set_T[0],xo_set_T[1], next_turn)))\n",
    "        \n",
    "    return equiv_state_ids\n",
    "\n",
    "def key_mapping(state: St) -> None:\n",
    "    #check if an equivalent state is already stored in map\n",
    "    equiv_states_keys = calculate_equivalent(from_xo_to_key(state))\n",
    "    equiv_key = None\n",
    "    for state_key in equiv_states_keys:\n",
    "        if state_key in states_map.keys():\n",
    "            equiv_key = state_key\n",
    "            break\n",
    "\n",
    "    if equiv_key == None:\n",
    "        state_key = from_xo_to_key(state)\n",
    "        states_map[state_key] = 0 #counter\n",
    "\n",
    "def generate_all_states() -> None:\n",
    "    \n",
    "    for el in list(product([-1,0,1], repeat=9)):\n",
    "        n_0 = len([0 for i in el if i == 0])\n",
    "        n_1 = len([1 for i in el if i == 1])\n",
    "        if 0<= n_0-n_1 <= 1: \n",
    "            next_player = n_0-n_1\n",
    "            x = set([])\n",
    "            o = set([])\n",
    "            for i,xo_ in enumerate(el):\n",
    "                if xo_ == 0:\n",
    "                    x = x|{i}\n",
    "                elif xo_ == 1:\n",
    "                    o = o|{i}\n",
    "            key_mapping(St(x, o, next_player))\n",
    "\n",
    "def from_ply_to_key(ply: Ply) -> int :#4 bits are enought to represent pos, fifth bit is turn 1/0\n",
    "    return (ply.turn<<4) + ply.pos\n",
    "\n",
    "def from_key_to_ply(key: int) -> Ply:\n",
    "    return Ply(key>>4,key-((key>>4)<<4))\n",
    "\n",
    "def make_ply(state_xo: St, ply: Ply):\n",
    "\n",
    "    assert state_xo.next_turn == ply.turn, \"error: wrong turn\"\n",
    "\n",
    "    if ply.turn == 0:\n",
    "        return St(state_xo.x|set({ply.pos}), state_xo.o, (ply.turn+1)%2)\n",
    "    else:\n",
    "        return St(state_xo.x, state_xo.o|set({ply.pos}), (ply.turn+1)%2)\n",
    "    \n",
    "def generate_all_actions() -> None:\n",
    "\n",
    "    for state_key in states_map.keys():\n",
    "        state_xo=from_key_to_xo(state_key)\n",
    "\n",
    "        for pos_ply in set(range(9)) - state_xo.x - state_xo.o:\n",
    "            \n",
    "            ply = Ply(state_xo.next_turn, pos_ply)\n",
    "            \n",
    "            next_state_xo = make_ply(state_xo, ply)\n",
    "            action_map[(state_key,from_ply_to_key(ply))] = static_eval(next_state_xo)\n",
    "            #in this way terminal move are chosen everytime by corresponding player\n",
    "            #(I can also go for higher gamma)\n",
    "\n",
    "generate_all_states() #4s 850 states\n",
    "my_print(f\"states generated: {len(states_map.keys())}\")\n",
    "\n",
    "generate_all_actions()\n",
    "my_print(f\"actions generated: {len(action_map.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random/random training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 2500/2500 [00:10<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi-trained/random training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 2500/2500 [00:11<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi-trained/semi-trained training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 2500/2500 [00:10<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained/semi-trained training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 2500/2500 [00:08<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained/trained training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 2500/2500 [00:10<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained/random training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 2500/2500 [00:07<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:0°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1  0]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [ 0  1  1]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1 -1  0]\n",
      " [-1  0 -1]\n",
      " [ 0  1  1]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1  0 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1  0 -1]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 0 -1 -1]]\n",
      "AI turn\n",
      "rotation:-180°, transpose: 0\n",
      "[[-1 -1  0]\n",
      " [ 0  1 -1]\n",
      " [-1  1 -1]]\n",
      "random turn\n",
      "[[-1 -1  0]\n",
      " [ 0  1 -1]\n",
      " [-1  1  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1  1  0]\n",
      " [ 0  1 -1]\n",
      " [-1  1  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1  0]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 0  1 -1]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1 -1  0]\n",
      " [-1  0  1]\n",
      " [ 0  1 -1]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:-180°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1  0]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1 -1  0]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 0 -1 -1]]\n",
      "AI turn\n",
      "rotation:-180°, transpose: 0\n",
      "[[-1 -1  0]\n",
      " [ 0  1 -1]\n",
      " [-1  1 -1]]\n",
      "random turn\n",
      "rotation:-180°, transpose: 1\n",
      "[[-1 -1  0]\n",
      " [ 1  1 -1]\n",
      " [-1  0  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1 -1  0]\n",
      " [ 1  1  1]\n",
      " [-1  0  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1 -1  1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [ 0 -1  1]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[ 0 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:-270°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1  0]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1 -1  0]]\n",
      "random turn\n",
      "rotation:0°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [ 0 -1  0]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [ 0  1  0]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 0  1  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1  1 -1]\n",
      " [-1  1  0]\n",
      " [ 0  1  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotation:-180°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1  0]]\n",
      "random turn\n",
      "rotation:0°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[ 0 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:-270°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1  0]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1 -1  0]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 0 -1 -1]]\n",
      "AI turn\n",
      "rotation:-180°, transpose: 0\n",
      "[[-1 -1  0]\n",
      " [ 0  1 -1]\n",
      " [-1  1 -1]]\n",
      "random turn\n",
      "rotation:-180°, transpose: 1\n",
      "[[-1 -1  0]\n",
      " [ 1  1 -1]\n",
      " [-1  0  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1 -1  0]\n",
      " [ 1  1  1]\n",
      " [-1  0  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1 -1]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  0 -1]\n",
      " [-1  1  0]]\n",
      "random turn\n",
      "rotation:0°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[ 0 -1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "GAME START\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "random turn\n",
      "rotation:-270°, transpose: 0\n",
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1  0]]\n",
      "AI turn\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1 -1  0]]\n",
      "random turn\n",
      "rotation:0°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1  0  0]]\n",
      "AI turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [ 0  0  1]]\n",
      "random turn\n",
      "rotation:-90°, transpose: 1\n",
      "[[-1 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 1  0  0]]\n",
      "AI turn\n",
      "FINAL BOARD\n",
      "[[-1 -1  1]\n",
      " [-1  1  0]\n",
      " [ 1  0  0]]\n",
      "victories ratio: 0.952\n",
      "draw ratio: 0.048\n",
      "defeats ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "N_GAMES = 2_500\n",
    "\n",
    "hit_map_action = {}\n",
    "#states map is now transformed to a counter that tell how many times we reached the state:\n",
    "for key in states_map.keys():\n",
    "    states_map[key] = static_eval(from_key_to_xo(key)) #avoid overflow\n",
    "\n",
    "for key in action_map.keys():\n",
    "    hit_map_action[key] = 0\n",
    "    action_map[key] = static_eval(make_ply(from_key_to_xo(key[0]), from_key_to_ply(key[1])))\n",
    "\n",
    "\n",
    "def softmax_stable(x: np.array) -> np.array: #takes np.array return np.array\n",
    "    return(np.exp(x - np.max(x)) / np.exp(x - np.max(x)).sum())\n",
    "\n",
    "\n",
    "def policy_ply(state: int, player: int, learned = False, stochastic = False) -> (int, int): \n",
    "    # can play random, deterministic trained, stochastic trained\n",
    "\n",
    "    state_xo = from_key_to_xo(state)\n",
    "    \n",
    "    assert (len(state_xo.x) + len(state_xo.o)) < 9, \"game already ended\"\n",
    "    assert static_eval(state_xo) == 0, \"someone already won\"\n",
    "    \n",
    "    equiv_states = calculate_equivalent(state)\n",
    "    for n_transform,equiv_state_key in enumerate(equiv_states): # we need to check from which state we start but since not all states are mapped we need to find the equivalent mapped\n",
    "        \n",
    "        if states_map.get(equiv_state_key) != None:\n",
    "            \n",
    "            equiv_state_xo = from_key_to_xo(equiv_state_key) # equiv state have different free positions\n",
    "            possible_pos = set(range(9)) - equiv_state_xo.x - equiv_state_xo.o    \n",
    "            \n",
    "            equiv_plys_credits = []\n",
    "            for ply_pos in possible_pos:\n",
    "                    \n",
    "                ply_on_equiv = Ply(equiv_state_xo.next_turn, ply_pos)\n",
    "                ply_on_equiv_key = from_ply_to_key(ply_on_equiv)\n",
    "                credit = action_map.get((equiv_state_key, ply_on_equiv_key))\n",
    "                equiv_plys_credits.append((ply_on_equiv_key, credit))\n",
    "\n",
    "            equiv_state_ply = (None, None)\n",
    "\n",
    "            if learned:\n",
    "\n",
    "                if stochastic:\n",
    "                    if player == 0:\n",
    "                        equiv_ply_key = np.random.choice(np.array([equiv_plys_credits[i][0] for i in range(len(equiv_plys_credits))]), p=softmax_stable(np.array([equiv_plys_credits[i][1] for i in range(len(equiv_plys_credits))])))\n",
    "                    else:\n",
    "                        equiv_ply_key = np.random.choice(np.array([equiv_plys_credits[i][0] for i in range(len(equiv_plys_credits))]), p=softmax_stable(np.array([-equiv_plys_credits[i][1] for i in range(len(equiv_plys_credits))])))\n",
    "                    equiv_state_ply = (equiv_state_key, equiv_ply_key) \n",
    "\n",
    "                else: #deterministic (pick best action based on value)\n",
    "                        \n",
    "                    if player == 0:\n",
    "                        best = -BIG_INT\n",
    "                    else:\n",
    "                        best =  BIG_INT\n",
    "\n",
    "                    for equiv_ply_credit in equiv_plys_credits:\n",
    "                            \n",
    "                        if (equiv_ply_credit[1]>best and player == 0) or (equiv_ply_credit[1]<best and player == 1):\n",
    "                            best = equiv_ply_credit[1]\n",
    "                            equiv_state_ply = (equiv_state_key, equiv_ply_credit[0])\n",
    "                        \n",
    "            else: #random (uniform probability for all possible actions)\n",
    "                \n",
    "                equiv_ply_key = np.random.choice(np.array([equiv_plys_credits[i][0] for i in range(len(equiv_plys_credits))]))\n",
    "                equiv_state_ply = (equiv_state_key, equiv_ply_key)\n",
    "\n",
    "            assert equiv_state_ply != (None, None), \"best move must exist\"\n",
    "                \n",
    "                \n",
    "            if DISPLAY_GAME:\n",
    "                    #at this stage the print of board doesn't apply automatically transformations\n",
    "                    #just tell what transformation is retrieved from action_map\n",
    "                    for i in range(4):\n",
    "                        for j in range(2):\n",
    "                            if n_transform == i*2+j:\n",
    "                                if i != 0 or j != 0:\n",
    "                                    my_print(f\"rotation:{-i*90}°, transpose: {j}\")\n",
    "                                          \n",
    "                    my_print(from_xo_to_board(equiv_state_xo.x,equiv_state_xo.o))\n",
    "                \n",
    "            return equiv_state_ply\n",
    "\n",
    "\n",
    "γ = 0.83\n",
    "\n",
    "def assign_rewards_monte_carlo(winner: int, ply_played_keys: [(int, int)]) -> None:\n",
    "    \n",
    "    reward = 1-winner*2 #map 0 to 1 and 1 to -1\n",
    "    \n",
    "    if winner == -1:\n",
    "        reward = 0\n",
    "    for i,state_ply_key in enumerate(list(ply_played_keys)[::-1]):\n",
    "        \n",
    "        total_discount = γ**i\n",
    "        #hyperbolic discount vs exponential discount γ**i, exponential is time invariant --> better \n",
    "        #tic tac toe has +1/-1/0 only at end so Gt = Re*(γ**distane_from_end) \n",
    "        hit_map_action[state_ply_key] += total_discount\n",
    "        action_map[state_ply_key] += 1/(hit_map_action[state_ply_key])*(reward*total_discount-action_map[state_ply_key]) #deepmind course lecture 4 minute 28\n",
    "        \n",
    "                    \n",
    "assign_rewards=assign_rewards_monte_carlo\n",
    "\n",
    "DISPLAY_GAME = False # useful only to display automatic plays\n",
    "\n",
    "my_print(\"random/random training\")\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    player = 0\n",
    "    ply_played_keys = []\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "        \n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "            \n",
    "        state_ply = policy_ply(state_prev, player, learned=False) \n",
    "        ply_played_keys.append(state_ply)\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "\n",
    "        player = (player+1)%2\n",
    "        \n",
    "    assign_rewards(winner, ply_played_keys)\n",
    "\n",
    "\n",
    "my_print(\"semi-trained/random training\")\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    player = 0\n",
    "    ply_played_keys = []\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "        \n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "            \n",
    "        state_ply = policy_ply(state_prev, player, learned=(player==(game%2)), stochastic=True) \n",
    "        ply_played_keys.append(state_ply)\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "\n",
    "        player = (player+1)%2\n",
    "        \n",
    "    assign_rewards(winner, ply_played_keys)\n",
    "        \n",
    "\n",
    "my_print(\"semi-trained/semi-trained training\")\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    player = 0\n",
    "    ply_played_keys = []\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "        \n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "            \n",
    "        state_ply = policy_ply(state_prev, player, learned=True, stochastic=True) \n",
    "        ply_played_keys.append(state_ply)\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "\n",
    "        player = (player+1)%2\n",
    "        \n",
    "    assign_rewards(winner, ply_played_keys)\n",
    "\n",
    "\n",
    "my_print(\"trained/semi-trained training\")\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    player = 0\n",
    "    ply_played_keys = []\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "        \n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "            \n",
    "        state_ply = policy_ply(state_prev, player, learned=True, stochastic=(player==(game%2))) \n",
    "        ply_played_keys.append(state_ply)\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "\n",
    "        player = (player+1)%2\n",
    "        \n",
    "    assign_rewards(winner, ply_played_keys)\n",
    "\n",
    "\n",
    "my_print(\"trained/trained training\")\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    player = 0\n",
    "    ply_played_keys = []\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "        \n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "            \n",
    "        state_ply = policy_ply(state_prev, player, learned=True, stochastic=False) \n",
    "        ply_played_keys.append(state_ply)\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "\n",
    "        player = (player+1)%2\n",
    "        \n",
    "    assign_rewards(winner, ply_played_keys)\n",
    "\n",
    "\n",
    "my_print(\"trained/random training\") #final training in the test situation\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    player = 0\n",
    "    ply_played_keys = []\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "        \n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "            \n",
    "        state_ply = policy_ply(state_prev, player, learned=(player==(game%2)), stochastic=False) \n",
    "        ply_played_keys.append(state_ply)\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "\n",
    "        player = (player+1)%2\n",
    "        \n",
    "    assign_rewards(winner, ply_played_keys)\n",
    "\n",
    "\n",
    "# TEST AGENT\n",
    "DISPLAY_GAME = True\n",
    "MAX_PRINT = 10\n",
    "N_GAMES = 10_000\n",
    "\n",
    "wins = 0\n",
    "draws = 0\n",
    "lose = 0\n",
    "for game in range(N_GAMES):\n",
    "    #ai_player = game%2 #half I start half random start\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "    player = 0\n",
    "    \n",
    "\n",
    "    if(game>=MAX_PRINT):\n",
    "        DISPLAY_GAME = False\n",
    "\n",
    "    if DISPLAY_GAME:\n",
    "        my_print(f\"GAME START\")\n",
    "\n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "        \n",
    "        state_ply = policy_ply(state_prev, player, player==(game%2))\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "        \n",
    "        if DISPLAY_GAME:\n",
    "            if player == (game%2):\n",
    "                my_print(\"AI turn\")\n",
    "            else:\n",
    "                my_print(\"random turn\")\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "        \n",
    "        player = (player+1)%2\n",
    "\n",
    "    if DISPLAY_GAME:\n",
    "        my_print(\"FINAL BOARD\")\n",
    "        my_print(from_xo_to_board(state_xo.x, state_xo.o))\n",
    "\n",
    "    if winner == (game%2):\n",
    "        wins +=1\n",
    "    elif winner == -1:\n",
    "        draws +=1\n",
    "    else:\n",
    "        lose += 1\n",
    "    \n",
    "my_print(f\"victories ratio: {wins/N_GAMES}\")\n",
    "my_print(f\"draw ratio: {draws/N_GAMES}\")\n",
    "my_print(f\"defeats ratio: {lose/N_GAMES}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained/random testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Game: 100%|\u001b[32m██████████████████████████████████████████████████\u001b[0m| 100000/100000 [06:16<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victories ratio: 0.95302\n",
      "draw ratio: 0.04698\n",
      "defeats ratio: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TEST AGENT ON LOT OF GAMES\n",
    "\n",
    "N_GAMES = 100_000\n",
    "DISPLAY_GAME = False\n",
    "\n",
    "wins = 0\n",
    "draws = 0\n",
    "lose = 0\n",
    "\n",
    "my_print(\"trained/random testing\") #final training in the test situation\n",
    "custom_bar_format = \"{l_bar}{bar:50}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "progress_bar = tqdm(range(N_GAMES),dynamic_ncols=True,desc=\"Game\",colour=\"green\",total=N_GAMES,mininterval=0.5,bar_format=custom_bar_format,ncols=100)\n",
    "\n",
    "for game in progress_bar:\n",
    "    #ai_player = game%2 #half I start half random start\n",
    "    winner = -1\n",
    "    state_prev = from_xo_to_key(St(set(),set(),0))\n",
    "    player = 0\n",
    "    \n",
    "\n",
    "    if(game>=MAX_PRINT):\n",
    "        DISPLAY_GAME = False\n",
    "\n",
    "    if DISPLAY_GAME:\n",
    "        my_print(f\"GAME START\")\n",
    "\n",
    "    for turn in range(9): #it finish after 9 ply maximum\n",
    "        \n",
    "        state_ply = policy_ply(state_prev, player, player==(game%2))\n",
    "        state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "        state_prev = from_xo_to_key(state_xo)\n",
    "        \n",
    "        if DISPLAY_GAME:\n",
    "            if player == (game%2):\n",
    "                my_print(\"AI turn\")\n",
    "            else:\n",
    "                my_print(\"random turn\")\n",
    "\n",
    "        if static_eval(state_xo) != 0:\n",
    "            winner=player\n",
    "            break\n",
    "        \n",
    "        player = (player+1)%2\n",
    "\n",
    "    if DISPLAY_GAME:\n",
    "        my_print(\"FINAL BOARD\")\n",
    "        my_print(from_xo_to_board(state_xo.x, state_xo.o))\n",
    "\n",
    "    if winner == (game%2):\n",
    "        wins +=1\n",
    "    elif winner == -1:\n",
    "        draws +=1\n",
    "    else:\n",
    "        lose += 1\n",
    "    \n",
    "my_print(f\"victories ratio: {wins/N_GAMES}\")\n",
    "my_print(f\"draw ratio: {draws/N_GAMES}\")\n",
    "my_print(f\"defeats ratio: {lose/N_GAMES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AGENT Q-Values\n",
    "\n",
    "# Save to file, suggested if lose rate == 0.0\n",
    "with open('data.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(action_map, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING AGENT Q-Values\n",
    "with open('data.pkl', 'rb') as pickle_file:\n",
    "    action_map = pickle.load(pickle_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can exit game by entering any not integer character\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game start\n",
      ". . . \n",
      ". . . \n",
      ". . . \n",
      "your turn\n",
      ". X . \n",
      ". . . \n",
      ". . . \n",
      "RL agent turn\n",
      ". X . \n",
      ". O . \n",
      ". . . \n",
      "your turn\n",
      ". X X \n",
      ". O . \n",
      ". . . \n",
      "RL agent turn\n",
      "O X X \n",
      ". O . \n",
      ". . . \n",
      "your turn\n",
      "O X X \n",
      "X O . \n",
      ". . . \n",
      "RL agent turn\n",
      "O X X \n",
      "X O . \n",
      ". . O \n",
      "\n",
      "I WON\n"
     ]
    }
   ],
   "source": [
    "# RUN PLAY AGAINST REAL PLAYER (use transform_V)\n",
    "transform_V = [] \n",
    "#lab10_b use a direct mapping between (state,action)->next_state->state_value, easier to understand, \n",
    "#but since only state has value that is independent by the previous state it gets worse results\n",
    "\n",
    "def rl_agent_ply(state: int) -> (int, int):\n",
    "\n",
    "    equiv_states_keys = calculate_equivalent(state)\n",
    "    \n",
    "    for n_transform,equiv_state_key in enumerate(equiv_states_keys): # we need to check from which state we start but since not all states are mapped we need to find the equivalent mapped\n",
    "        #rotation is done before move\n",
    "        if states_map.get(equiv_state_key) != None:\n",
    "            \n",
    "            equiv_state_xo = from_key_to_xo(equiv_state_key) # equiv state have different free positions\n",
    "            possible_pos = set(range(9)) - equiv_state_xo.x - equiv_state_xo.o\n",
    "\n",
    "            if player == 0:\n",
    "                best = -BIG_INT\n",
    "            else:\n",
    "                best =  BIG_INT\n",
    "                \n",
    "            equiv_state_best_ply = (None, None)\n",
    "            for ply_pos in possible_pos:\n",
    "                    \n",
    "                ply_on_equiv = Ply(equiv_state_xo.next_turn, ply_pos)\n",
    "                ply_on_equiv_key = from_ply_to_key(ply_on_equiv)\n",
    "                    \n",
    "                credits = action_map.get((equiv_state_key, ply_on_equiv_key))\n",
    "                if credits != None:\n",
    "                    if (credits>best and player == 0) or (credits<best and player == 1):\n",
    "                        best = credits\n",
    "                        equiv_state_best_ply = (equiv_state_key, ply_on_equiv_key)\n",
    "                \n",
    "            assert equiv_state_best_ply != (None, None), \"best move must exist\"\n",
    "                \n",
    "                \n",
    "            for i in range(4):\n",
    "                for j in range(2):\n",
    "                    if n_transform == i*2+j:\n",
    "                        if i!=0 or j!=0:\n",
    "                            transform_V.append((i,j))\n",
    "                            \n",
    "            return equiv_state_best_ply\n",
    "    \n",
    "    assert False,\"best move must exist\"\n",
    "\n",
    "def human_ply(state: int, pos: int) -> (int, int):\n",
    "\n",
    "    equiv_states_keys = calculate_equivalent(state)\n",
    "    turn = from_key_to_xo(state).next_turn\n",
    "    #new_pos=equivalent_move(pos, state.next_turn) # first need to calculate new_pos as equivalent_move_until_now than from there you can calculate it based on additional the new board rotation\n",
    "\n",
    "    for n_transform,equiv_state_key in enumerate(equiv_states_keys):\n",
    "        if states_map.get(equiv_state_key)!=None: # after you find valid state you have to find if tha move is mapped\n",
    "            \n",
    "            #rotation is done before move\n",
    "\n",
    "            for i in range(4):\n",
    "                for j in range(2):\n",
    "                    if n_transform == i*2+j:\n",
    "                        \n",
    "                        if i!=0 or j!=0:\n",
    "                            transform_V.append((i,j))\n",
    "                           \n",
    "                        ply_on_equiv_key = equivalent_move(from_ply_to_key(Ply(turn, pos)))\n",
    "                        \n",
    "                        if (from_key_to_ply(ply_on_equiv_key).pos in from_key_to_xo(equiv_state_key).x) or (from_key_to_ply(ply_on_equiv_key).pos in from_key_to_xo(equiv_state_key).o):\n",
    "                            my_print(\"invalid move, position already taken\")\n",
    "                            return (None, None)\n",
    "                        \n",
    "                        return (equiv_state_key, ply_on_equiv_key )\n",
    "\n",
    "    assert False, \"invalid move, unrecognized\"\n",
    "\n",
    "def display_board(board: np.array, transforms=transform_V) -> None:\n",
    "    orig_orient_board = deepcopy(board)\n",
    "    # current board is transition_board\n",
    "    # but need to be mapped on equivalent board as orig_orient_board->transition_V->transition_board, \n",
    "    # so transition_board->(transition_V[::-1])^-1->orig_orient_board is done on reversed tv\n",
    "    \n",
    "    for (rot,t) in transforms[::-1]:\n",
    "        if t == 1:\n",
    "            orig_orient_board = orig_orient_board.T\n",
    "        orig_orient_board = np.rot90(orig_orient_board, k=-rot)\n",
    "\n",
    "    (x_orig, o_orig)=from_board_to_xo(orig_orient_board)\n",
    "    \n",
    "    display(x_orig, o_orig)\n",
    "\n",
    "def equivalent_move(ply_key: int) -> int:\n",
    "\n",
    "    player, pos = from_key_to_ply(ply_key)\n",
    "\n",
    "    # current board is transition_board -> move is done on orig_oriented_board\n",
    "    # but need to be mapped on equivalent move as: move on orig_orient_board->transition_V->move on transition_board\n",
    "    supp_board = np.zeros((3,3),dtype=np.uint8)\n",
    "    supp_board[pos//3][pos%3] = 1\n",
    "\n",
    "    for (rot,t) in transform_V:\n",
    "        supp_board = np.rot90(supp_board, k=rot)\n",
    "        if t == 1:\n",
    "            supp_board = supp_board.T\n",
    "\n",
    "    supp_board=supp_board.flatten()\n",
    "\n",
    "    for new_pos,val in enumerate(supp_board):\n",
    "        if val == 1:\n",
    "            return from_ply_to_key(Ply(player, new_pos))\n",
    "\n",
    "    assert False, \"not here\"\n",
    "        \n",
    "\n",
    "DISPLAY_GAME = False\n",
    "\n",
    "my_print(\"you can exit game by entering any not integer character\")\n",
    "\n",
    "your_turn = int(input(\"Do you choose X(player 0) or Y(player 1)? type 0/1\"))\n",
    "\n",
    "winner = -1\n",
    "state_xo = St(set(),set(),0)\n",
    "player = 0\n",
    "\n",
    "my_print(\"game start\")\n",
    "\n",
    "for turn in range(9): #it finish after 9 ply maximum \n",
    "\n",
    "    display_board(from_xo_to_board(state_xo.x, state_xo.o))    \n",
    "\n",
    "    if (player == your_turn):\n",
    "        my_print(\"your turn\") \n",
    "        pos = int(input(\"CHOOSE A POSITION 0 TO 8 in which you want to play (0=top-left, 2=top-right, 3=bottom-left, 4=bottom-right)\"))\n",
    "        while( pos not in [n for n in range(9)]):\n",
    "            my_print(\"invalid character\")\n",
    "            pos = int(input(\"CHOOSE A POSITION 0 TO 8 in which you want to play (0=top-left, 2=top-right, 3=bottom-left, 4=bottom-right)\"))\n",
    "        state_ply = human_ply(from_xo_to_key(state_xo), pos)\n",
    "        while (state_ply == (None,None)):\n",
    "            pos = int(input(\"CHOOSE A POSITION 0 TO 8 in which you want to play (0=top-left, 2=top-right, 3=bottom-left, 4=bottom-right)\"))\n",
    "            while( pos not in [n for n in range(9)]):\n",
    "                my_print(\"invalid character\")\n",
    "                pos = int(input(\"CHOOSE A POSITION 0 TO 8 in which you want to play (0=top-left, 2=top-right, 3=bottom-left, 4=bottom-right)\"))\n",
    "            state_ply = human_ply(from_xo_to_key(state_xo), pos)\n",
    "    else:\n",
    "        my_print(\"RL agent turn\")\n",
    "        state_ply = rl_agent_ply(from_xo_to_key(state_xo))\n",
    "    \n",
    "    \n",
    "    state_xo = make_ply(from_key_to_xo(state_ply[0]), from_key_to_ply(state_ply[1]))\n",
    "    \n",
    "    if static_eval(state_xo) != 0:\n",
    "        winner=player\n",
    "        break\n",
    "        \n",
    "    player = (player+1)%2\n",
    "\n",
    "display_board(from_xo_to_board(state_xo.x, state_xo.o))  \n",
    "\n",
    "if winner == -1:\n",
    "    my_print(\"\\nDRAW\")\n",
    "else:\n",
    "    if winner == your_turn:\n",
    "        my_print(\"\\nYOU WON\")\n",
    "    else:\n",
    "        my_print(\"\\nI WON\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
