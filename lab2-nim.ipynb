{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from random import randint,choice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "    @property\n",
    "    def rows_l(self) -> list:\n",
    "        return self._rows\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None: #ply is move remove \"num_object\" object from row \"row\"\n",
    "        row, num_objects = ply\n",
    "        assert num_objects>0\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the following code address the proble to solve with a good probability of success (around 99%).\n",
    "The version optimized is the one in witch the the player who plays the optimal solution always win (50% only if also the other is playing optimal) so in order to obtain this result the Nim sum should always be == 0\n",
    "and the player who wins is the one that remove last piece(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evolutionary strategy\n",
    "* STRATEGY 1: computes the xor of all elements (number of match for row) except maximum one\n",
    "  than subtract the xor from the max if xor is lower than the maximum (no parameter to optimize)\n",
    "* STRATEGY 2: find the objective probability pvec=[p0,p1,...,pn-1] to remove all elements from the \n",
    "  smallest i row, and then use it\n",
    "  * Example:\n",
    "    p0 is the probability of removing all from the smallest <br>\n",
    "    p1 is the probability of removing all form the 2nd smallest row <br>\n",
    "    pn-1 is the probability of removing all from largest row <br>\n",
    "  \n",
    "  Other techniques such as softmax(pvec) are used to normalize the vector such that sum(pvec) = 1 and for each i pi between (0,1) <br>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth of genealogical tree, if TRAIN_EPOCHS too high can lead to underflow\n",
    "TRAIN_EPOCHS = 10\n",
    "#accuracy with which I want to measure the win rate of my strategy\n",
    "ACCURACY = 10000\n",
    "#number of \"child\" in offspring\n",
    "LAMBDA = 10\n",
    "#limit to the number of random number generation \n",
    "#1. p can be approximatively 0 for some rows <e-40\n",
    "#2. some p can be invalid (ex. I have at least 1 row with 0 matches)\n",
    "MAX_RAND = 100\n",
    "\n",
    "def softmax(x,xtot):\n",
    "    return np.exp(x)/sum(np.exp(np.array(xtot)))\n",
    "\n",
    "def adaptive(grid:Nim,comparison_strategy):\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    #since I have no idea about the variance to use I apply self adaptation\n",
    "    state = deepcopy(grid)\n",
    "    l = len(state.rows)\n",
    "   \n",
    "    #uniform start\n",
    "    prob0 = [1/l for _ in range(l)]\n",
    "    var0 = [3/l for _ in range(l)]\n",
    "\n",
    "    genome = {\"past_win\":0.5,\"p\":[prob0[i] for i in range(l)], \"sigma_p\":[var0[i] for i in range(l)]}\n",
    "    \n",
    "    #win ratio is phenotype, not genome, but is practivcal to add it to genome\n",
    "    evolutionary = None\n",
    "    \n",
    "    for step in range(TRAIN_EPOCHS):\n",
    "        \n",
    "        \n",
    "        result = [] #vector of tuples containing (n_win,[p1,p2,p3,p4,p5,...])\n",
    "        for child in range(LAMBDA): #for each child define a new play_function with a different set of parameters\n",
    "\n",
    "            #suggested at lesson\n",
    "            lr_p = 1/np.sqrt(step+1)\n",
    "            #separate learning rate, gaussian mutated for each p in the vector\n",
    "            \n",
    "            new_sigma_p = [genome[\"sigma_p\"][i]*np.exp(lr_p*random.normalvariate()) for i in range (len(genome[\"sigma_p\"]))]\n",
    "            new_p = [p+random.normalvariate(sigma=new_sigma_p[i]) for i,p in enumerate(genome[\"p\"])]\n",
    "            new_p = [softmax(p,new_p) for p in new_p]\n",
    "\n",
    "            #logging.info(step)\n",
    "            \n",
    "            def evolutionary(state):\n",
    "                \n",
    "                max_val = max(deepcopy(state.rows_l))\n",
    "                state_no_max=[nel for nel in deepcopy(state.rows_l)]\n",
    "                state_no_max.remove(max_val)\n",
    "                #code of nim_sum applied just to all rows except the one with max number of matches\n",
    "                tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state_no_max ])\n",
    "                xor = tmp.sum(axis=0) % 2 #a sum[0,1]%2 is a xor\n",
    "                xor_val = int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "                #DIM is size passed to Nim constuctor -> Nim(DIM)\n",
    "                if xor_val<max_val:\n",
    "                    #if possible apply a good \"greedy\" strategy -> O(32xDIM)\n",
    "                    #(32 is cost of sum along rows)\n",
    "                    return Nimply(*(state.rows_l.index(max_val),max_val-xor_val))\n",
    "                else:\n",
    "                    #have to find a good linear strategy for this case (optimal is brute force O(32xDIMxDIMxDIM) -> we want O(32xDIMxN_RAND))\n",
    "                    #brute force is O(32xDIMxDIM) since I have to check with nim_sum all the sum(i*2+1) for i in range(DIM)\n",
    "                    #n.moves = 1+3+5+7+9+11+13+... \n",
    "                    #1 -> 1\n",
    "                    #2 -> 1+3=4\n",
    "                    #3 -> 1+3+5=4+5=9\n",
    "                    #4 -> 1+3+5+7=9+7=16\n",
    "                    #5 -> 1+3+5+7+9=16+9=25\n",
    "                    #6 -> 1+3+5+7+9+11=25+11=36\n",
    "                    #7 -> 1+3+5+7+9+11+13=36+13=49\n",
    "                    #...\n",
    "                    #strategy 2\n",
    "                    prow = new_p # newly generated random mutation\n",
    "                    row_map = sorted(enumerate(state.rows),key=lambda r: r[1])# ordered by growing number of elements (the original order may not correspond)\n",
    "                    num_objects = 0 # useful to stop cicle in case of finding a valid row\n",
    "                    n_rand = 0 # stop generating after n_rand >= RAND_MAX\n",
    "                                \n",
    "                    while num_objects == 0:\n",
    "\n",
    "                        row = np.random.choice(range(len(prow)),p=prow) # random choice with probability p[i] to pick element i \n",
    "                        num_objects = state.rows[row_map[row][0]] # row_map[row][0] is the actual row, row_map[row][1] is the number of elements in the actual row \n",
    "                        \n",
    "                        n_rand+=1\n",
    "\n",
    "                        if n_rand>=MAX_RAND:\n",
    "\n",
    "                            first_invalid_index = l #find the number of remaining row !=0\n",
    "                            for i in range(l-1,-1,-1):\n",
    "                                if row_map[i][1] == 0:\n",
    "                                    first_invalid_index = i\n",
    "                                    break\n",
    "                            \n",
    "                            more_probable_left_value = max(prow[first_invalid_index+1:l]) # choose among the remainings the one with max probability\n",
    "                            more_probable_left = row_map[prow.index(more_probable_left_value)] # retrive (orig_column,n_matches_orig_column)\n",
    "                            return Nimply(*(more_probable_left[0],more_probable_left[1])) #remove all matches from the most probabale\n",
    "\n",
    "                    return Nimply(*(row_map[row][0],num_objects))    \n",
    "\n",
    "            win_count=0\n",
    "            for i in range (ACCURACY): \n",
    "\n",
    "                strategy = (comparison_strategy, evolutionary)\n",
    "                player = i%2\n",
    "                state = deepcopy(grid)#reset grid\n",
    "                #simulate game\n",
    "                while state:\n",
    "                \n",
    "                    ply = strategy[player](state)\n",
    "                    state.nimming(ply)\n",
    "                    player = 1 - player\n",
    "                    \n",
    "                #add victory\n",
    "                if (1-player)==1:#modified rules\n",
    "                    win_count+=1\n",
    "            \n",
    "            result.append((win_count/ACCURACY,new_p,new_sigma_p))\n",
    "\n",
    "        #1st attempt (1,LAMBDA) #60%\n",
    "        #best_child = max(result,key=lambda c: c[0] )\n",
    "        #genome = {\"past_win\":best_child[0] , \"p\":best_child[1] , \"sigma_p\":new_sigma_p}\n",
    "\n",
    "        #2nd attempt (1+LAMBDA) (keep code of 2nd attempt)\n",
    "        result.append((genome[\"past_win\"],genome[\"p\"],genome[\"sigma_p\"]))\n",
    "        best_child = max(result,key=lambda c: c[0] )\n",
    "        genome = {\"past_win\":best_child[0] , \"p\":best_child[1] , \"sigma_p\":best_child[2]}\n",
    "        \n",
    "\n",
    "    #logging.info(f\"win ratio:{genome['win_ratio']}\")\n",
    "    logging.info(f\"genome:{genome}\")\n",
    "\n",
    "    def evolutionary(state):\n",
    "        #same as previous except line with comment\n",
    "        max_val = max(state.rows)\n",
    "        max_val = max(deepcopy(state.rows_l))\n",
    "        state_no_max=[nel for nel in deepcopy(state.rows_l)]\n",
    "        state_no_max.remove(max_val)\n",
    "        tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state_no_max ])\n",
    "        xor = tmp.sum(axis=0) % 2 \n",
    "        xor_val = int(\"\".join(str(_) for _ in xor), base=2)\n",
    "        if xor_val<max_val:\n",
    "            return Nimply(*(state.rows_l.index(max_val),max_val-xor_val))\n",
    "        else:\n",
    "            prow = genome[\"p\"]#taken by genome\n",
    "            row_map = sorted(enumerate(state.rows),key=lambda r: r[1])\n",
    "            num_objects=0\n",
    "            n_rand = 0\n",
    "            while num_objects == 0:\n",
    "                row = np.random.choice(range(len(prow)),p=prow)\n",
    "                num_objects=state.rows[row_map[row][0]]\n",
    "                n_rand+=1\n",
    "                if n_rand>=MAX_RAND:\n",
    "                    first_invalid_index = l\n",
    "                    for i in range(l-1,-1,-1):\n",
    "                        if row_map[i][1] == 0:\n",
    "                            first_invalid_index = i\n",
    "                            break\n",
    "                    more_probable_left_value = max(prow[first_invalid_index+1:l])\n",
    "                    more_probable_left = row_map[prow.index(more_probable_left_value)]\n",
    "                    return Nimply(*(more_probable_left[0],more_probable_left[1])) \n",
    "            \n",
    "            return Nimply(*(row_map[row][0],num_objects))\n",
    "\n",
    "    return evolutionary\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: optimal function has changed in this version of Nim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2 #a sum[0,1]%2 is a xor\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())#basically at random between all plays\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: 1-player wins implies that player who wins is the last to remove piece(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: Player 0 won 5000 times!\n",
      "INFO:root:status: Player 0 won 1000 times!\n",
      "INFO:root:status: Player 0 won 480 times!\n",
      "INFO:root:status: Player 0 won 779 times!\n",
      "INFO:root:status: Player 0 won 500 times!\n",
      "INFO:root:status: Player 0 won 0 times!\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "strategy = ( optimal, optimal)#half win\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#2\n",
    "strategy = ( optimal, pure_random )#always win\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#3\n",
    "strategy = ( pure_random, pure_random )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#4\n",
    "strategy = ( gabriele, pure_random )#50% no -> better >70%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#5\n",
    "strategy = ( gabriele, gabriele )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "\n",
    "#6\n",
    "strategy = ( gabriele, optimal )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: gabriele strategy reveal as a good strategy only for this version of Nim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: Player 0 won 7655 times!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#4 -> better test\n",
    "strategy = ( gabriele, pure_random )#50% no -> better >70%\n",
    "count = 0 \n",
    "for i in range(10000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:genome:{'past_win': 0.9924, 'p': [0.0034152162850083706, 0.00191667111433166, 0.0016054633859851064, 0.007933697365537439, 0.9818414334621578, 0.0018430832399723832, 0.0014444351470073022], 'sigma_p': [3.055279916662707, 0.42463799193054746, 0.062466636164550865, 2.3865773595545487, 2.600026416211226, 0.1168868412140859, 0.4189884094400319]}\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "#it doesn't make sense to train on optimal at least in first phase\n",
    "\n",
    "nim = Nim(7)\n",
    "evolutionary=adaptive(nim,pure_random)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9 11 13>\n",
      "INFO:root:status: evolutionary result: 99.194% won!\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "nim = Nim(7)\n",
    "strategy = (pure_random, evolutionary)\n",
    "#strategy 2 win more than gabriele\n",
    "\n",
    "TEST_SAMPLE = 100000\n",
    "\n",
    "logging.info(f\"init : {nim}\")\n",
    "\n",
    "win_count = 0\n",
    "for i in range(TEST_SAMPLE):\n",
    "    nim = Nim(7)\n",
    "    player = i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    \n",
    "    if (1-player)==1:\n",
    "        win_count+=1\n",
    "\n",
    "\n",
    "logging.info(f\"status: evolutionary result: {win_count/TEST_SAMPLE*100}% won!\")\n",
    "#around 99% with Nim(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First strategy standalone test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9 11 13>\n",
      "INFO:root:status: good_greedy result: 96.503% won!\n"
     ]
    }
   ],
   "source": [
    "def good_greedy(state):\n",
    "        \n",
    "    max_val = max(deepcopy(state.rows_l))\n",
    "    state_no_max=[nel for nel in deepcopy(state.rows_l)]\n",
    "    state_no_max.remove(max_val)\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state_no_max ])\n",
    "    xor = tmp.sum(axis=0) % 2 #a sum[0,1]%2 is a xor\n",
    "    xor_val = int(\"\".join(str(_) for _ in xor), base=2)\n",
    "        \n",
    "    if xor_val<max_val:\n",
    "        return Nimply(*(state.rows_l.index(max_val),max_val-xor_val))\n",
    "    else:\n",
    "        #have to find a good linear strategy for this case (optimal is brute force O(DIMxDIM) -> we want O(DIM))\n",
    "        row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "        return Nimply(*(row, state.rows[row]))\n",
    "    \n",
    "\n",
    "strategy = (pure_random, good_greedy)\n",
    "\n",
    "TEST_SAMPLE = 100000\n",
    "\n",
    "nim = Nim(7)\n",
    "logging.info(f\"init : {nim}\")\n",
    "\n",
    "win_count = 0\n",
    "for i in range(TEST_SAMPLE):\n",
    "    nim = Nim(7)\n",
    "    player = i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    \n",
    "    if (1-player)==1:\n",
    "        win_count+=1\n",
    "\n",
    "\n",
    "logging.info(f\"status: good_greedy result: {win_count/TEST_SAMPLE*100}% won!\")\n",
    "#96.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:genome:{'past_win': 1.0, 'p': [6.965857624572689e-36, 7.395199290538448e-42, 1.0, 1.4515858843350588e-43, 9.264196711159191e-46], 'sigma_p': [46.674365406576555, 7.7412135789972245, 35.183244607025614, 4.059243549459197, 27.821583003159287]}\n",
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:status: evolutionary result: 10000 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "#train againist gabriele\n",
    "\n",
    "nim = Nim(5)\n",
    "evolutionary=adaptive(nim,gabriele)\n",
    "\n",
    "nim = Nim(5)\n",
    "strategy = (gabriele, evolutionary)\n",
    "\n",
    "TEST_SAMPLE = 10000\n",
    "\n",
    "logging.info(f\"init : {nim}\")\n",
    "\n",
    "win_count = 0\n",
    "for i in range(TEST_SAMPLE):\n",
    "    nim = Nim(5)\n",
    "    player = i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    \n",
    "    if (1-player)==1:\n",
    "        win_count+=1\n",
    "\n",
    "logging.info(f\"status: evolutionary result: {win_count} won!\")\n",
    "#training againist gabriele -> lead to 50/50 win first time\n",
    "\n",
    "#againist gabriele it always win since always execute first startegy (that put in safe condition the opponent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide version\n",
    "### Task 2.1\n",
    "### nim_sum != 0 and the player who cannot take a match wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2 #a sum[0,1]%2 is a xor\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())#basically at random between all plays\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the 3 given strategy, in the case of winner = who cannot remove matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: Player 0 won 490 times!\n",
      "INFO:root:status: Player 0 won 751 times!\n",
      "INFO:root:status: Player 0 won 508 times!\n",
      "INFO:root:status: Player 0 won 220 times!\n",
      "INFO:root:status: Player 0 won 500 times!\n",
      "INFO:root:status: Player 0 won 110 times!\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "strategy = ( optimal, optimal)#half win\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#2\n",
    "strategy = ( optimal, pure_random )#always win\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#3\n",
    "strategy = ( pure_random, pure_random )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#4\n",
    "strategy = ( gabriele, pure_random )#50% no -> better >70%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#5\n",
    "strategy = ( gabriele, gabriele )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "\n",
    "#6\n",
    "strategy = ( gabriele, optimal )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "\n",
    "#conclusion: strategy is optimal in the extent that leaves the possibility to play a move with ns==0 to the opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: Player 0 won 6079 times!\n"
     ]
    }
   ],
   "source": [
    "def not_gabriele(state: Nim) -> Nimply: # gabriele didn't use an optimal strategy for this rules-> pick 1 from lowest row is better\n",
    "    \"\"\"Pick always 1 from the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*(max(possible_moves, key=lambda m: (-m[1]))[0],1))\n",
    "\n",
    "\n",
    "#4\n",
    "strategy = ( not_gabriele, pure_random )#50% no -> better >70%\n",
    "count = 0 \n",
    "for i in range(10000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if player==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth of genealogical tree, if TRAIN_EPOCHS too high can lead to underflow\n",
    "TRAIN_EPOCHS = 100\n",
    "#accuracy with which I want to measure the win rate of my strategy\n",
    "ACCURACY = 1000\n",
    "#number of \"child\" in offspring\n",
    "LAMBDA = 3\n",
    "#limit to the number of random number generation \n",
    "#1. p can be approximatively 0 for some rows <e-40\n",
    "#2. some p can be invalid (ex. I have at least 1 row with 0 matches)\n",
    "MAX_RAND = 100\n",
    "\n",
    "def softmax(x,xtot):\n",
    "    return np.exp(x)/sum(np.exp(np.array(xtot)))\n",
    "\n",
    "def adaptive(grid:Nim,comparison_strategy):\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    #since I have no idea about the variance to use I apply self adaptation\n",
    "    state = deepcopy(grid)\n",
    "    l = len(state.rows)\n",
    "   \n",
    "    #uniform start\n",
    "    prob0 = [1/l for _ in range(l)]\n",
    "    var0 = [3/l for _ in range(l)]\n",
    "\n",
    "    genome = {\"past_win\":0.0,\"p\":[prob0[i] for i in range(l)], \"sigma_p\":[var0[i] for i in range(l)]}\n",
    "    \n",
    "    #win ratio is phenotype, not genome, but is practivcal to add it to genome\n",
    "    evolutionary = None\n",
    "    \n",
    "    for step in range(TRAIN_EPOCHS):\n",
    "        \n",
    "        \n",
    "        result = [] #vector of tuples containing (n_win,[p1,p2,p3,p4,p5,...])\n",
    "        for child in range(LAMBDA): #for each child define a new play_function with a different set of parameters\n",
    "\n",
    "            #suggested at lesson\n",
    "            lr_p = 1/np.sqrt(step+1)\n",
    "            #separate learning rate, gaussian mutated for each p in the vector\n",
    "            \n",
    "            new_sigma_p = [genome[\"sigma_p\"][i]*np.exp(lr_p*random.normalvariate()) for i in range (len(genome[\"sigma_p\"]))]\n",
    "            new_p = [p+random.normalvariate(sigma=new_sigma_p[i]) for i,p in enumerate(genome[\"p\"])]\n",
    "            new_p = [softmax(p,new_p) for p in new_p]\n",
    "\n",
    "            #logging.info(step)\n",
    "            \n",
    "            def evolutionary(state):\n",
    "                 \n",
    "                #strategy 2\n",
    "                prow = new_p # newly generated random mutation\n",
    "                row_map = sorted(enumerate(state.rows), key=lambda r: r[1])# ordered by growing number of elements (the original order may not correspond)\n",
    "                num_objects = 0 # useful to stop cicle in case of finding a valid row\n",
    "                n_rand = 0 # stop generating after n_rand >= RAND_MAX\n",
    "                \n",
    "                while num_objects == 0:\n",
    "\n",
    "                    row = np.random.choice(range(len(prow)),p=prow) # random choice with probability p[i] to pick element i \n",
    "                    num_objects = state.rows[row_map[row][0]] # row_map[row][0] is the actual row, row_map[row][1] is the number of elements in the actual row \n",
    "                        \n",
    "                    n_rand+=1\n",
    "\n",
    "                    if n_rand>=MAX_RAND:\n",
    "\n",
    "                        first_invalid_index = l-1 #find the number of remaining row !=0\n",
    "                        for i in range(l-1,-1,-1):\n",
    "                            if row_map[i][1] == 0:\n",
    "                                first_invalid_index = i\n",
    "                                break\n",
    "                            \n",
    "                        more_probable_left_value = max(prow[first_invalid_index+1:l]) # choose among the remainings the one with max probability\n",
    "                        more_probable_left_index = row_map[prow.index(more_probable_left_value)][0] # retrive (orig_column,n_matches_orig_column)\n",
    "                        return Nimply(*(more_probable_left_index,1)) #remove all matches from the most probabale\n",
    "                    \n",
    "                return Nimply(*(row_map[row][0],1))    \n",
    "\n",
    "            win_count=0\n",
    "            for i in range (ACCURACY): \n",
    "\n",
    "                strategy = (comparison_strategy, evolutionary)\n",
    "                player = i%2\n",
    "                state = deepcopy(grid)#reset grid\n",
    "                #simulate game\n",
    "                while state:\n",
    "                \n",
    "                    ply = strategy[player](state)\n",
    "                    state.nimming(ply)\n",
    "                    player = 1 - player\n",
    "                    \n",
    "                #add victory\n",
    "                if player==1:#modified rules\n",
    "                    win_count+=1\n",
    "            \n",
    "            result.append((win_count/ACCURACY,new_p,new_sigma_p))\n",
    "\n",
    "        #1st attempt (1,LAMBDA) #60%\n",
    "        #best_child = max(result,key=lambda c: c[0] )\n",
    "        #genome = {\"past_win\":best_child[0] , \"p\":best_child[1] , \"sigma_p\":new_sigma_p}\n",
    "\n",
    "        #2nd attempt (1+LAMBDA) (keep code of 2nd attempt)\n",
    "        result.append((genome[\"past_win\"],genome[\"p\"],genome[\"sigma_p\"]))\n",
    "        best_child = max(result,key=lambda c: c[0] )\n",
    "        genome = {\"past_win\":best_child[0] , \"p\":best_child[1] , \"sigma_p\":best_child[2]}\n",
    "        \n",
    "\n",
    "    #logging.info(f\"win ratio:{genome['win_ratio']}\")\n",
    "    logging.info(f\"genome:{genome}\")\n",
    "\n",
    "    def evolutionary(state):\n",
    "        #same as previous except line with comment\n",
    "        \n",
    "        prow = genome[\"p\"]#taken by genome\n",
    "        row_map = sorted(enumerate(state.rows), key=lambda r: r[1])# ordered by growing number of elements (the original order may not correspond)\n",
    "        num_objects = 0 # useful to stop cicle in case of finding a valid row\n",
    "        n_rand = 0 # stop generating after n_rand >= RAND_MAX\n",
    "                \n",
    "        while num_objects == 0:\n",
    "\n",
    "            row = np.random.choice(range(len(prow)),p=prow) # random choice with probability p[i] to pick element i \n",
    "            num_objects = state.rows[row_map[row][0]] # row_map[row][0] is the actual row, row_map[row][1] is the number of elements in the actual row \n",
    "                        \n",
    "            n_rand+=1\n",
    "            if n_rand>=MAX_RAND:\n",
    "\n",
    "                first_invalid_index = l-1 #find the number of remaining row !=0\n",
    "                for i in range(l-1,-1,-1):\n",
    "                    if row_map[i][1] == 0:\n",
    "                        first_invalid_index = i\n",
    "                        break\n",
    "                            \n",
    "                more_probable_left_value = max(prow[first_invalid_index+1:l]) # choose among the remainings the one with max probability\n",
    "                more_probable_left_index = row_map[prow.index(more_probable_left_value)][0] # retrive (orig_column,n_matches_orig_column)\n",
    "                return Nimply(*(more_probable_left_index,1)) #remove all matches from the most probabale\n",
    "                    \n",
    "        return Nimply(*(row_map[row][0],1))    \n",
    "\n",
    "    return evolutionary\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:genome:{'past_win': 0.652, 'p': [0.025740317851924342, 0.8724555013657693, 0.07121693812091899, 0.030583291187654453, 3.9514737329499265e-06], 'sigma_p': [0.3537607666507349, 1.6743770492337033, 1.0091555040750952, 0.2496151498755137, 21.650565634527762]}\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "#it doesn't make sense to train on optimal at least in first phase\n",
    "\n",
    "nim = Nim(5)\n",
    "evolutionary=adaptive(nim,pure_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:status: evolutionary result: 62.21% won!\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "nim = Nim(5)\n",
    "strategy = (pure_random, evolutionary)\n",
    "#strategy 2 win more than gabriele\n",
    "\n",
    "TEST_SAMPLE = 100000\n",
    "\n",
    "logging.info(f\"init : {nim}\")\n",
    "\n",
    "win_count = 0\n",
    "for i in range(TEST_SAMPLE):\n",
    "    nim = Nim(5)\n",
    "    player = i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    \n",
    "    if player==1:\n",
    "        win_count+=1\n",
    "\n",
    "\n",
    "logging.info(f\"status: evolutionary result: {win_count/TEST_SAMPLE*100}% won!\")\n",
    "#gain of 2% against random if compared to not gabriele"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
