{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None: #ply is move remove \"num_object\" object from row \"row\"\n",
    "        row, num_objects = ply\n",
    "        assert num_objects>0\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_EPOCHS = 1000\n",
    "ACCURACY = 100\n",
    "LAMBDA = 5\n",
    "MAX_RAND = 20\n",
    "\n",
    "def softmax(x,xtot):\n",
    "    return np.exp(x)/sum(np.exp(np.array(xtot)))\n",
    "\n",
    "def adaptive(state: Nim,comparison_strategy) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    #since I have no idea about the variance to use I apply self adaptation\n",
    "    l = len(state.rows)\n",
    "    #genome = {\"win_ratio\": 0.5, \"sigma_win\": 0.01, \"p\":[1/l for _ in range(l)], \"sigma_p\":[3/l for _ in range(l)]}\n",
    "    genome = {\"past_win\":0.5,\"p\":[softmax(1/l,[1/l for _ in range(l)]) for _ in range(l)], \"sigma_p\":[4/l for _ in range(l)]}\n",
    "\n",
    "    evolutionary = None\n",
    "    for step in range(TRAIN_EPOCHS):\n",
    "        \n",
    "        \n",
    "        result = [] #vector of tuples containing (n_win,[p1,p2,p3,p4,p5,...])\n",
    "        for child in range(LAMBDA): #for each child define a new play_function with a different set of parameters\n",
    "\n",
    "            #suggested at lesson\n",
    "            lr_p = 1/np.sqrt(step+1)\n",
    "            #separate learning rate, gaussian mutated for each p in the vector\n",
    "            \n",
    "            new_sigma_p = [genome[\"sigma_p\"][i]*np.exp(lr_p*random.normalvariate()) for i in range (len(genome[\"sigma_p\"]))]\n",
    "            new_p = [p+random.normalvariate(sigma=new_sigma_p[i]) for i,p in enumerate(genome[\"p\"])]\n",
    "            new_p = [softmax(p,new_p) for p in new_p]\n",
    "\n",
    "            #logging.info(step)\n",
    "            \n",
    "            def evolutionary(state):\n",
    "                \n",
    "                prow = new_p\n",
    "                row_map = sorted(enumerate(state.rows),key=lambda r: r[1])#numero di elementi crescente\n",
    "                num_objects=0\n",
    "                n_rand = 0\n",
    "                \n",
    "                while num_objects == 0:\n",
    "                    row = np.random.choice(range(len(prow)),p=prow)\n",
    "                    num_objects=state.rows[row_map[row][0]]\n",
    "                    n_rand+=1\n",
    "                    if n_rand>=MAX_RAND:\n",
    "                        max_el = max(state.rows)\n",
    "                        return Nimply(*(state.rows.index(max_el),max_el))\n",
    "                \n",
    "                return Nimply(*(row_map[row][0],num_objects))\n",
    "                    \n",
    "            win_count=0\n",
    "            for i in range (ACCURACY): \n",
    "\n",
    "                strategy = (comparison_strategy, evolutionary)\n",
    "                player = i%2\n",
    "                state = Nim(5)\n",
    "                #simulate game\n",
    "                while state:\n",
    "                \n",
    "                    ply = strategy[player](state)\n",
    "                    state.nimming(ply)\n",
    "                    player = 1 - player\n",
    "                    \n",
    "                #add victory\n",
    "                if (1-player)==1:#modified rules\n",
    "                    win_count+=1\n",
    "            \n",
    "            result.append((win_count/ACCURACY,new_p,new_sigma_p))\n",
    "\n",
    "        #1st attempt (1,LAMBDA) #60%\n",
    "        #best_child = max(result,key=lambda c: c[0] )\n",
    "        #genome = {\"past_win\":best_child[0] , \"p\":best_child[1] , \"sigma_p\":new_sigma_p}\n",
    "\n",
    "        #2nd attempt (1+LAMBDA) (keep code of 2nd attempt)\n",
    "        result.append((genome[\"past_win\"],genome[\"p\"],genome[\"sigma_p\"]))\n",
    "        best_child = max(result,key=lambda c: c[0] )\n",
    "        genome = {\"past_win\":best_child[0] , \"p\":best_child[1] , \"sigma_p\":best_child[2]}\n",
    "        \n",
    "\n",
    "    #logging.info(f\"win ratio:{genome['win_ratio']}\")\n",
    "    logging.info(f\"genome:{genome}\")\n",
    "\n",
    "    def evolutionary(state):\n",
    "        \n",
    "        prow = genome[\"p\"]\n",
    "        row_map = sorted(enumerate(state.rows),key=lambda r: r[1])#numero di elementi crescente\n",
    "        num_objects=0\n",
    "        n_rand = 0\n",
    "\n",
    "        while num_objects == 0:\n",
    "            row = np.random.choice(range(len(prow)),p=prow)\n",
    "            num_objects=state.rows[row_map[row][0]]\n",
    "            n_rand+=1\n",
    "            if n_rand>=MAX_RAND:\n",
    "                max_el = max(state.rows)\n",
    "                return Nimply(*(state.rows.index(max_el),max_el))\n",
    "        \n",
    "        return Nimply(*(row_map[row][0],num_objects))\n",
    "\n",
    "    return evolutionary\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2 #a sum[0,1]%2 is a xor\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())#basically at random between all plays\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: Player 0 won 500 times!\n",
      "INFO:root:status: Player 0 won 1000 times!\n",
      "INFO:root:status: Player 0 won 502 times!\n",
      "INFO:root:status: Player 0 won 762 times!\n",
      "INFO:root:status: Player 0 won 500 times!\n",
      "INFO:root:status: Player 0 won 0 times!\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "strategy = ( optimal, optimal)#half win\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#2\n",
    "strategy = ( optimal, pure_random )#always win\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#3\n",
    "strategy = ( pure_random, pure_random )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#4\n",
    "strategy = ( gabriele, pure_random )#50% no -> better >70%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "#5\n",
    "strategy = ( gabriele, gabriele )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n",
    "\n",
    "\n",
    "#6\n",
    "strategy = ( gabriele, optimal )#50%\n",
    "count = 0 \n",
    "for i in range(1000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: Player 0 won 7621 times!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#4 -> better test\n",
    "strategy = ( gabriele, pure_random )#50% no -> better >70%\n",
    "count = 0 \n",
    "for i in range(10000):\n",
    "    \n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player=i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player #next player\n",
    "    if (1-player)==0:\n",
    "        count+=1\n",
    "\n",
    "logging.info(f\"status: Player {0} won {count} times!\")#rule change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:genome:{'past_win': 0.91, 'p': [0.384249863485209, 0.22158842562762432, 0.22650985590920084, 0.15212204277265962, 0.015529812205306153], 'sigma_p': [1.0004558032774495, 0.24745396641626868, 0.2917381228897459, 0.20056299197427388, 0.9734738582898244]}\n",
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:status: evolutionary result: 8209 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "#it doesn't make sense to train on optimal at least in first phase\n",
    "\n",
    "#nim = Nim(5)\n",
    "evolutionary=adaptive(nim,pure_random)\n",
    "\n",
    "nim = Nim(5)\n",
    "strategy = (pure_random, evolutionary)\n",
    "\n",
    "TEST_SAMPLE = 10000\n",
    "\n",
    "logging.info(f\"init : {nim}\")\n",
    "player = 0\n",
    "win_count = 0\n",
    "for i in range(TEST_SAMPLE):\n",
    "    nim = Nim(5)\n",
    "    player = i%2\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    \n",
    "    if (1-player)==1:\n",
    "        win_count+=1\n",
    "\n",
    "\n",
    "logging.info(f\"status: evolutionary result: {win_count} won!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if i can remove from highest \n",
    "#to obtain xor of other elements -> found best move\n",
    "#else\n",
    "#highest element has for sure highest bit at 1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
